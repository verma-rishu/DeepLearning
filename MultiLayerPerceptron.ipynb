{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WgzYdyhY4_mN"
      },
      "source": [
        "<h1><center>Foundations of Deep Learning</center></h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40nCWOmj7Xjz"
      },
      "source": [
        "<h2><center>Multi Layer Perceptron</center><h2>\n",
        "\n",
        "Multiplayer Perceptron is a feed forward neural network composed of multiple layers of affine transformations followed by non linearity function. Each layer of an MLP is defined as:\n",
        "$$\n",
        "z^{(l)} = W^{(l)}x^{(l-1)} + b^{(l)}\n",
        "$$ \n",
        "\n",
        "$$\n",
        "x^{(l)} = f(z^{(l)})\n",
        "$$\n",
        "\n",
        "Here, $l$ denotes the layer of MLP, $W$ and $b$ are the trainable parameters called *weight* and *bias* respectively\n",
        "\n",
        "ReLU or Rectified Linear Unit is the most common non linear layer used with MLP.\n",
        "More about ReLU can be found here: https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekbdxA4KtmSS"
      },
      "source": [
        "In this assignment you are required to do the following:\n",
        "\n",
        "+ Create an MLP\n",
        "  + Write the *forward* function for affine transformation\n",
        "  + Write the *backward* function (to calculate gradients) for the affine transformation\n",
        "  + Create a Neural Network by stacking these transformations\n",
        "\n",
        "+ Train the Neural Network on Fashion MNIST Dataset\n",
        "  + Write Loss Function for the training\n",
        "  + Write parameter update routine\n",
        "  + Run Validation \n",
        "  + Plot Train and Validation Loss Curves using Matplotlib \n",
        "\n",
        "+ Testing the Neural Network\n",
        "  + Change the *seed* and train the neural network 10 times\n",
        "  + Report the mean and variance over 10 trials on the following metrics:\n",
        "    + Accuracy\n",
        "    + Precision\n",
        "    + Recall\n",
        "    + F1\n",
        "    + ROC curve\n",
        "\n",
        "+ Change the number of parameters in the Neural Network \n",
        "  + Train a underfit model\n",
        "  + Train a overfit model\n",
        "  + Demostrate the difference between overfitting and underfitting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFkP9B5-rwFe"
      },
      "outputs": [],
      "source": [
        "#@\n",
        "Name = \"Rishu Verma\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJYSA_Cm1fnV",
        "outputId": "3f463b57-ae77-4c42-caa8-f1ef64453ed9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.8/dist-packages (0.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.1+cu116)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f4374098e10>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as tnn\n",
        "import numpy as np\n",
        "!pip install torchmetrics\n",
        "\n",
        "# select device as cuda\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "# set random seeds\n",
        "seed = 1234 ## change this seed when you run trials\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVBLiKBUxK68"
      },
      "source": [
        "### Gradient Update\n",
        "To update gradients, from the equation of affine transformation we have:\n",
        "\n",
        "$$\n",
        "z^{(l)} = W^{(l)}x^{(l-1)} + b\n",
        "$$ \n",
        "\n",
        "We can calulate all the partial derivations in the following fashion\n",
        "\n",
        "$$\n",
        "\\frac{\\partial z^{(l)}}{\\partial x^{(l-1)}} = W^{(l)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{\\partial z^{(l)}}{\\partial W^{(l)}} = x^{(l-1)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{\\partial z^{(l)}}{\\partial b^{(l)}} = 1\n",
        "$$\n",
        "\n",
        "To write the *backward* function, we need one more step. *backward* functon takes *grad_output* as its input. It is the backward flow of gradients coming from the final output $\\hat y$ and can be mathematically expressed as:\n",
        "$$\n",
        "  grad\\_output = \\frac{\\partial \\hat y}{\\partial z^{(l)}}\n",
        "$$\n",
        "\n",
        "*backward* functions gives out three values:\n",
        "\n",
        "$$\n",
        "grad\\_x = \\frac{\\partial \\hat y}{\\partial x^{(l-1)}} = \\frac{\\partial \\hat y}{\\partial z^{(l)}} \\frac{\\partial z^{(l)}}{\\partial x^{(l-1)}} \n",
        "$$\n",
        "\n",
        "$$\n",
        "grad\\_w = \\frac{\\partial \\hat y}{\\partial W^{(l)}} = \\frac{\\partial \\hat y}{\\partial z^{(l)}} \\frac{\\partial z^{(l)}}{\\partial W^{(l)}}\n",
        "$$\n",
        "\n",
        "\n",
        "$$\n",
        "grad\\_b = \\frac{\\partial \\hat y}{\\partial b^{(l)}} =  \\frac{\\partial \\hat y}{\\partial z^{(l)}} \\frac{\\partial z^{(l)}}{\\partial b^{(l)}}\n",
        "$$\n",
        "\n",
        "In the code below, update the *forward* and *backward* functions of class LinearFunction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pcgiaXw35f71"
      },
      "outputs": [],
      "source": [
        "class LinearFunction(torch.autograd.Function):\n",
        "  @staticmethod\n",
        "  def forward(ctx, x, W, b):\n",
        "    \"\"\"\n",
        "    # x -> input matrix of size n_samples x sdim\n",
        "    # W -> transformation matrix\n",
        "    # b -> bias term \n",
        "    \"\"\"\n",
        "    ctx.save_for_backward(x, W, b)\n",
        "    # Write your affine transformation here:\n",
        "    #-------------------\n",
        "    xW = torch.matmul(x, W)\n",
        "    z = torch.add(xW,b)\n",
        "    #-------------------\n",
        "    return z\n",
        "    \n",
        "  @staticmethod\n",
        "  def backward(ctx, grad_output):\n",
        "    x, W, b = ctx.saved_tensors\n",
        "   \n",
        "    # Write gradient updates here:\n",
        "    #----------------------------\n",
        "    \"\"\"\n",
        "    The transpose of the W matrix is taken to match the dimensions of the two matrix to support matrix multiplication\n",
        "    \"\"\"\n",
        "    grad_x = torch.matmul(grad_output, W.t())\n",
        "    grad_w = torch.matmul(x.t(), grad_output)\n",
        "    grad_b = grad_output\n",
        "    #-----------------------------\n",
        "    return grad_x, grad_w, grad_b\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0-GkEJs19ml"
      },
      "source": [
        "Class CustomLinearLayer uses previously defined LinearFunction to create one layer of Neural Network. Look at the initial values given to $W$ and $b$.\n",
        "You do not need to change anything in this class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ksWyV7mSK15f"
      },
      "outputs": [],
      "source": [
        "class CustomLinearLayer(torch.nn.Module):\n",
        "  def __init__(self, in_features, out_features):\n",
        "    super(CustomLinearLayer, self).__init__()\n",
        "    self.in_features = in_features\n",
        "    self.out_features = out_features\n",
        "    w = torch.normal(mean = 0, std = 0.1, size = [in_features, out_features], requires_grad=True)\n",
        "    b = torch.full([out_features], 0.01, requires_grad=True)\n",
        "    w = torch.nn.Parameter(w)\n",
        "    b = torch.nn.Parameter(b)\n",
        "    self.register_parameter('w', w)\n",
        "    self.register_parameter('b', b)\n",
        "    self.linear_function = LinearFunction.apply\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.linear_function(x, self.w, self.b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXWwi0a02frQ"
      },
      "source": [
        "In the Neural Network class below class Below, Add two linear layers of the following sizes:\n",
        "+ 784 x 512\n",
        "+ 512 x 10\n",
        "\n",
        "In the forward function, \n",
        "+ Apply layer_1 on input\n",
        "+ Apply activation function on the result\n",
        "+ Apply layer_2 on the result\n",
        "+ Apply Softmax and return the final result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "E5M3gwT7LDLy"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    # Add Linear layers below \n",
        "    #-----------------------------------\n",
        "    '''\n",
        "      Using the CustomLinearLayer to declare the new layers in the NeuralNetwork.\n",
        "    '''\n",
        "    self.layer_1 = CustomLinearLayer(784,512)\n",
        "    self.layer_2 = CustomLinearLayer(512,10)\n",
        "    # ------------------------------------\n",
        "    self.activation = torch.nn.ReLU()\n",
        "    self.softmax = torch.nn.Softmax(dim=-1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    # Apply layers defined above:\n",
        "    #-------------------------------\n",
        "    output = self.layer_1(x) #Apply layer_1 on input\n",
        "    output = self.activation(output) #Apply activation function on the result\n",
        "    output = self.layer_2(output) #Apply layer_2 on the result (: output)\n",
        "    output = self.softmax(output) #Apply Softmax and return the final result\n",
        "    #-------------------------------\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH5-K2PP33lK"
      },
      "source": [
        "Fasion MNIST dataset is a set of grayscale images categorized into 10 classes. To train our neural network, first we need to define loss function. $y$ is the ground truth class label and $probs$ is the probability distribution given by our Neural Network over 10 classes, update the *forward* function of loss class below. \n",
        "\n",
        "$$\n",
        "ce\\_loss = -\\frac{1}{{\\#samples}}\\sum^{\\#samples}_i y_i.\\log(probs_i)\n",
        "$$\n",
        "\n",
        "*Hint*: Try representing $y$ as one hot vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Mme5RblpOpYf"
      },
      "outputs": [],
      "source": [
        "class CrossEntropyLoss(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CrossEntropyLoss, self).__init__()\n",
        "  \n",
        "  def forward(self, probs, y):\n",
        "    #Write loss function here:\n",
        "    #-------------------------------\n",
        "    '''\n",
        "      Implenting the CrossEntropyLoss for 10 classes (classes is taken from the size of \"probs\") \n",
        "      and samples will be the batchsize on which the network is trained and loss is calcluated.\n",
        "\n",
        "      It is observed that the number of samples may not always be equal to the batch_size as:\n",
        "      samples = len(dataset)/batchsize and if they are not perfect multiples then the last batch\n",
        "      of the data will have size less than the batchsize.\n",
        "    '''\n",
        "    number_of_classes = probs.shape[1] \n",
        "    number_of_samples = y.size()[0] \n",
        "    one_hot_vector_y = torch.nn.functional.one_hot(y,number_of_classes)\n",
        "    loss = -torch.div(torch.sum(torch.multiply(one_hot_vector_y, torch.log(probs))), number_of_samples)\n",
        "    #-------------------------------\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9OvSv0bazhlg"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "     Downloading the Data\n",
        "'''\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "EleFGZ8W4wGM",
        "outputId": "82cf6e57-e8b3-4c66-99d1-027a488fe2db"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x576 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ90GGxc58X5"
      },
      "source": [
        "Fashion MNIST dataset loaded from pytorch APIs only has two sets: train and test. Split the train data into train and validation sets with 50K samples in train and 10K samples in validation set. The data split should be random.\n",
        "\n",
        "*Hint* Look for a function in *torch.utils.data*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BachxlStz4E1"
      },
      "outputs": [],
      "source": [
        "# split mnist trainset into two sets: mnist trainset -> 50000 , mnist validation set -> 10000\n",
        "#----------------\n",
        "'''\n",
        "      Spliting the training data as per the instructions with training_set as 50000 and validation set = 10000\n",
        "'''\n",
        "train_data, val_data = torch.utils.data.random_split(training_data, [50000, 10000])\n",
        "#----------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSeXx9qL66UU",
        "outputId": "16ba4cab-b151-40e0-9873-435c56bc0e93"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[0][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LbhN71ej1Ry8"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "      model initialization \n",
        "'''\n",
        "model = NeuralNetwork().cuda()\n",
        "ce_loss = CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh0sY9487KoF"
      },
      "source": [
        "1) The gradients we calculated in the start can be accessed by iterating over model.parameters() as *params.grad*. Write the parameter update rule in the training code below: \n",
        "\n",
        "$$\n",
        "param := param - learning\\_rate*gradient\n",
        "$$\n",
        "\n",
        "2) Write validation loop which runs every epoch and prints the following metrics on validation set:\n",
        "  + Accuracy\n",
        "  + Precision\n",
        "  + Recall\n",
        "  + F1 \n",
        "  + roc_auc\n",
        "\n",
        "3) Store the training loss and validation loss in each iteration and plot a graph comparing them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uNL16slmMTST",
        "outputId": "76384fae-876b-4580-8f86-ea17026cb2ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/10 Iteration 0/49 Loss 3.6421902179718018: \n",
            "Epoch 0/10 Iteration 1/49 Loss 2.8335654735565186: \n",
            "Epoch 0/10 Iteration 2/49 Loss 2.489055633544922: \n",
            "Epoch 0/10 Iteration 3/49 Loss 2.36944580078125: \n",
            "Epoch 0/10 Iteration 4/49 Loss 2.2263412475585938: \n",
            "Epoch 0/10 Iteration 5/49 Loss 2.039961814880371: \n",
            "Epoch 0/10 Iteration 6/49 Loss 1.9673542976379395: \n",
            "Epoch 0/10 Iteration 7/49 Loss 1.9270508289337158: \n",
            "Epoch 0/10 Iteration 8/49 Loss 1.909238338470459: \n",
            "Epoch 0/10 Iteration 9/49 Loss 1.829696536064148: \n",
            "Epoch 0/10 Iteration 10/49 Loss 1.736072301864624: \n",
            "Epoch 0/10 Iteration 11/49 Loss 1.6891040802001953: \n",
            "Epoch 0/10 Iteration 12/49 Loss 1.6831843852996826: \n",
            "Epoch 0/10 Iteration 13/49 Loss 1.6354825496673584: \n",
            "Epoch 0/10 Iteration 14/49 Loss 1.6609687805175781: \n",
            "Epoch 0/10 Iteration 15/49 Loss 1.546505331993103: \n",
            "Epoch 0/10 Iteration 16/49 Loss 1.5746090412139893: \n",
            "Epoch 0/10 Iteration 17/49 Loss 1.5222103595733643: \n",
            "Epoch 0/10 Iteration 18/49 Loss 1.5270293951034546: \n",
            "Epoch 0/10 Iteration 19/49 Loss 1.5160634517669678: \n",
            "Epoch 0/10 Iteration 20/49 Loss 1.4762182235717773: \n",
            "Epoch 0/10 Iteration 21/49 Loss 1.4277840852737427: \n",
            "Epoch 0/10 Iteration 22/49 Loss 1.420271873474121: \n",
            "Epoch 0/10 Iteration 23/49 Loss 1.3812944889068604: \n",
            "Epoch 0/10 Iteration 24/49 Loss 1.4099160432815552: \n",
            "Epoch 0/10 Iteration 25/49 Loss 1.3824234008789062: \n",
            "Epoch 0/10 Iteration 26/49 Loss 1.329432725906372: \n",
            "Epoch 0/10 Iteration 27/49 Loss 1.3598614931106567: \n",
            "Epoch 0/10 Iteration 28/49 Loss 1.2869887351989746: \n",
            "Epoch 0/10 Iteration 29/49 Loss 1.3237316608428955: \n",
            "Epoch 0/10 Iteration 30/49 Loss 1.2886197566986084: \n",
            "Epoch 0/10 Iteration 31/49 Loss 1.2482259273529053: \n",
            "Epoch 0/10 Iteration 32/49 Loss 1.2516343593597412: \n",
            "Epoch 0/10 Iteration 33/49 Loss 1.2749043703079224: \n",
            "Epoch 0/10 Iteration 34/49 Loss 1.2298707962036133: \n",
            "Epoch 0/10 Iteration 35/49 Loss 1.199073314666748: \n",
            "Epoch 0/10 Iteration 36/49 Loss 1.175027847290039: \n",
            "Epoch 0/10 Iteration 37/49 Loss 1.1827633380889893: \n",
            "Epoch 0/10 Iteration 38/49 Loss 1.2051677703857422: \n",
            "Epoch 0/10 Iteration 39/49 Loss 1.2086212635040283: \n",
            "Epoch 0/10 Iteration 40/49 Loss 1.1417934894561768: \n",
            "Epoch 0/10 Iteration 41/49 Loss 1.1067324876785278: \n",
            "Epoch 0/10 Iteration 42/49 Loss 1.1499913930892944: \n",
            "Epoch 0/10 Iteration 43/49 Loss 1.1410813331604004: \n",
            "Epoch 0/10 Iteration 44/49 Loss 1.1514228582382202: \n",
            "Epoch 0/10 Iteration 45/49 Loss 1.1634063720703125: \n",
            "Epoch 0/10 Iteration 46/49 Loss 1.1595313549041748: \n",
            "Epoch 0/10 Iteration 47/49 Loss 1.100645899772644: \n",
            "Epoch 0/10 Iteration 48/49 Loss 1.1063220500946045: \n",
            "Epoch 0/10 Accuracy 0.6227022409439087 Precision 0.6123673915863037: Recall 0.6227022409439087 F1 0.6090500354766846 ROC_AUC 0.9305838942527771\n",
            "Epoch 1/10 Iteration 0/49 Loss 1.1173522472381592: \n",
            "Epoch 1/10 Iteration 1/49 Loss 1.103272795677185: \n",
            "Epoch 1/10 Iteration 2/49 Loss 1.0658587217330933: \n",
            "Epoch 1/10 Iteration 3/49 Loss 1.1049913167953491: \n",
            "Epoch 1/10 Iteration 4/49 Loss 1.0985673666000366: \n",
            "Epoch 1/10 Iteration 5/49 Loss 1.0585858821868896: \n",
            "Epoch 1/10 Iteration 6/49 Loss 1.034149408340454: \n",
            "Epoch 1/10 Iteration 7/49 Loss 1.05790114402771: \n",
            "Epoch 1/10 Iteration 8/49 Loss 1.0976977348327637: \n",
            "Epoch 1/10 Iteration 9/49 Loss 1.0589702129364014: \n",
            "Epoch 1/10 Iteration 10/49 Loss 1.033712387084961: \n",
            "Epoch 1/10 Iteration 11/49 Loss 1.009735345840454: \n",
            "Epoch 1/10 Iteration 12/49 Loss 1.0213404893875122: \n",
            "Epoch 1/10 Iteration 13/49 Loss 1.0295382738113403: \n",
            "Epoch 1/10 Iteration 14/49 Loss 1.0396168231964111: \n",
            "Epoch 1/10 Iteration 15/49 Loss 0.9741941094398499: \n",
            "Epoch 1/10 Iteration 16/49 Loss 1.0375399589538574: \n",
            "Epoch 1/10 Iteration 17/49 Loss 0.9864515066146851: \n",
            "Epoch 1/10 Iteration 18/49 Loss 1.0284491777420044: \n",
            "Epoch 1/10 Iteration 19/49 Loss 1.0150599479675293: \n",
            "Epoch 1/10 Iteration 20/49 Loss 1.0077298879623413: \n",
            "Epoch 1/10 Iteration 21/49 Loss 0.9770614504814148: \n",
            "Epoch 1/10 Iteration 22/49 Loss 0.9917545318603516: \n",
            "Epoch 1/10 Iteration 23/49 Loss 0.9765269756317139: \n",
            "Epoch 1/10 Iteration 24/49 Loss 1.0302051305770874: \n",
            "Epoch 1/10 Iteration 25/49 Loss 0.9936473965644836: \n",
            "Epoch 1/10 Iteration 26/49 Loss 0.9624885320663452: \n",
            "Epoch 1/10 Iteration 27/49 Loss 0.9960004091262817: \n",
            "Epoch 1/10 Iteration 28/49 Loss 0.9393760561943054: \n",
            "Epoch 1/10 Iteration 29/49 Loss 1.00795316696167: \n",
            "Epoch 1/10 Iteration 30/49 Loss 0.952434778213501: \n",
            "Epoch 1/10 Iteration 31/49 Loss 0.9314272403717041: \n",
            "Epoch 1/10 Iteration 32/49 Loss 0.9409328699111938: \n",
            "Epoch 1/10 Iteration 33/49 Loss 0.9828643202781677: \n",
            "Epoch 1/10 Iteration 34/49 Loss 0.940855860710144: \n",
            "Epoch 1/10 Iteration 35/49 Loss 0.9097020626068115: \n",
            "Epoch 1/10 Iteration 36/49 Loss 0.9035211801528931: \n",
            "Epoch 1/10 Iteration 37/49 Loss 0.934456467628479: \n",
            "Epoch 1/10 Iteration 38/49 Loss 0.9403944611549377: \n",
            "Epoch 1/10 Iteration 39/49 Loss 0.942318856716156: \n",
            "Epoch 1/10 Iteration 40/49 Loss 0.89153653383255: \n",
            "Epoch 1/10 Iteration 41/49 Loss 0.8686893582344055: \n",
            "Epoch 1/10 Iteration 42/49 Loss 0.9084566831588745: \n",
            "Epoch 1/10 Iteration 43/49 Loss 0.9016745090484619: \n",
            "Epoch 1/10 Iteration 44/49 Loss 0.9238013029098511: \n",
            "Epoch 1/10 Iteration 45/49 Loss 0.9485490322113037: \n",
            "Epoch 1/10 Iteration 46/49 Loss 0.9490540027618408: \n",
            "Epoch 1/10 Iteration 47/49 Loss 0.8833065629005432: \n",
            "Epoch 1/10 Iteration 48/49 Loss 0.9059121608734131: \n",
            "Epoch 1/10 Accuracy 0.6868796348571777 Precision 0.6792103052139282: Recall 0.6868796348571777 F1 0.6774517893791199 ROC_AUC 0.949833333492279\n",
            "Epoch 2/10 Iteration 0/49 Loss 0.9197635650634766: \n",
            "Epoch 2/10 Iteration 1/49 Loss 0.9088121056556702: \n",
            "Epoch 2/10 Iteration 2/49 Loss 0.8732978701591492: \n",
            "Epoch 2/10 Iteration 3/49 Loss 0.9112831354141235: \n",
            "Epoch 2/10 Iteration 4/49 Loss 0.9177586436271667: \n",
            "Epoch 2/10 Iteration 5/49 Loss 0.8869551420211792: \n",
            "Epoch 2/10 Iteration 6/49 Loss 0.8642563223838806: \n",
            "Epoch 2/10 Iteration 7/49 Loss 0.8856199383735657: \n",
            "Epoch 2/10 Iteration 8/49 Loss 0.9211413860321045: \n",
            "Epoch 2/10 Iteration 9/49 Loss 0.882754921913147: \n",
            "Epoch 2/10 Iteration 10/49 Loss 0.8779169917106628: \n",
            "Epoch 2/10 Iteration 11/49 Loss 0.8511692881584167: \n",
            "Epoch 2/10 Iteration 12/49 Loss 0.8616039752960205: \n",
            "Epoch 2/10 Iteration 13/49 Loss 0.8784071803092957: \n",
            "Epoch 2/10 Iteration 14/49 Loss 0.8749998807907104: \n",
            "Epoch 2/10 Iteration 15/49 Loss 0.8232505917549133: \n",
            "Epoch 2/10 Iteration 16/49 Loss 0.8913424015045166: \n",
            "Epoch 2/10 Iteration 17/49 Loss 0.8371481895446777: \n",
            "Epoch 2/10 Iteration 18/49 Loss 0.8812117576599121: \n",
            "Epoch 2/10 Iteration 19/49 Loss 0.8679277896881104: \n",
            "Epoch 2/10 Iteration 20/49 Loss 0.8690851330757141: \n",
            "Epoch 2/10 Iteration 21/49 Loss 0.8358721733093262: \n",
            "Epoch 2/10 Iteration 22/49 Loss 0.8594484925270081: \n",
            "Epoch 2/10 Iteration 23/49 Loss 0.8465906977653503: \n",
            "Epoch 2/10 Iteration 24/49 Loss 0.9070987701416016: \n",
            "Epoch 2/10 Iteration 25/49 Loss 0.862891674041748: \n",
            "Epoch 2/10 Iteration 26/49 Loss 0.8374964594841003: \n",
            "Epoch 2/10 Iteration 27/49 Loss 0.8687814474105835: \n",
            "Epoch 2/10 Iteration 28/49 Loss 0.8150563836097717: \n",
            "Epoch 2/10 Iteration 29/49 Loss 0.894569993019104: \n",
            "Epoch 2/10 Iteration 30/49 Loss 0.8300513625144958: \n",
            "Epoch 2/10 Iteration 31/49 Loss 0.813791811466217: \n",
            "Epoch 2/10 Iteration 32/49 Loss 0.825652003288269: \n",
            "Epoch 2/10 Iteration 33/49 Loss 0.870010495185852: \n",
            "Epoch 2/10 Iteration 34/49 Loss 0.8293504118919373: \n",
            "Epoch 2/10 Iteration 35/49 Loss 0.7978404760360718: \n",
            "Epoch 2/10 Iteration 36/49 Loss 0.7965620756149292: \n",
            "Epoch 2/10 Iteration 37/49 Loss 0.8327373266220093: \n",
            "Epoch 2/10 Iteration 38/49 Loss 0.8304024934768677: \n",
            "Epoch 2/10 Iteration 39/49 Loss 0.8292773365974426: \n",
            "Epoch 2/10 Iteration 40/49 Loss 0.7857128381729126: \n",
            "Epoch 2/10 Iteration 41/49 Loss 0.7682148218154907: \n",
            "Epoch 2/10 Iteration 42/49 Loss 0.8030646443367004: \n",
            "Epoch 2/10 Iteration 43/49 Loss 0.7976123690605164: \n",
            "Epoch 2/10 Iteration 44/49 Loss 0.8227312564849854: \n",
            "Epoch 2/10 Iteration 45/49 Loss 0.8511370420455933: \n",
            "Epoch 2/10 Iteration 46/49 Loss 0.8528294563293457: \n",
            "Epoch 2/10 Iteration 47/49 Loss 0.7834131717681885: \n",
            "Epoch 2/10 Iteration 48/49 Loss 0.8127209544181824: \n",
            "Epoch 2/10 Accuracy 0.7318297028541565 Precision 0.7237617373466492: Recall 0.7318297028541565 F1 0.7242040634155273 ROC_AUC 0.957629382610321\n",
            "Epoch 3/10 Iteration 0/49 Loss 0.8275760412216187: \n",
            "Epoch 3/10 Iteration 1/49 Loss 0.8186608552932739: \n",
            "Epoch 3/10 Iteration 2/49 Loss 0.7829936742782593: \n",
            "Epoch 3/10 Iteration 3/49 Loss 0.8203025460243225: \n",
            "Epoch 3/10 Iteration 4/49 Loss 0.8294077515602112: \n",
            "Epoch 3/10 Iteration 5/49 Loss 0.8030941486358643: \n",
            "Epoch 3/10 Iteration 6/49 Loss 0.7816246747970581: \n",
            "Epoch 3/10 Iteration 7/49 Loss 0.8011854887008667: \n",
            "Epoch 3/10 Iteration 8/49 Loss 0.8302531242370605: \n",
            "Epoch 3/10 Iteration 9/49 Loss 0.7930243611335754: \n",
            "Epoch 3/10 Iteration 10/49 Loss 0.7998365163803101: \n",
            "Epoch 3/10 Iteration 11/49 Loss 0.7705178260803223: \n",
            "Epoch 3/10 Iteration 12/49 Loss 0.7794467210769653: \n",
            "Epoch 3/10 Iteration 13/49 Loss 0.7990950345993042: \n",
            "Epoch 3/10 Iteration 14/49 Loss 0.7900799512863159: \n",
            "Epoch 3/10 Iteration 15/49 Loss 0.7452924251556396: \n",
            "Epoch 3/10 Iteration 16/49 Loss 0.8142246603965759: \n",
            "Epoch 3/10 Iteration 17/49 Loss 0.758703887462616: \n",
            "Epoch 3/10 Iteration 18/49 Loss 0.8013191223144531: \n",
            "Epoch 3/10 Iteration 19/49 Loss 0.7895705103874207: \n",
            "Epoch 3/10 Iteration 20/49 Loss 0.7946641445159912: \n",
            "Epoch 3/10 Iteration 21/49 Loss 0.7583178281784058: \n",
            "Epoch 3/10 Iteration 22/49 Loss 0.78822922706604: \n",
            "Epoch 3/10 Iteration 23/49 Loss 0.7745354175567627: \n",
            "Epoch 3/10 Iteration 24/49 Loss 0.83901047706604: \n",
            "Epoch 3/10 Iteration 25/49 Loss 0.7896823883056641: \n",
            "Epoch 3/10 Iteration 26/49 Loss 0.7675412893295288: \n",
            "Epoch 3/10 Iteration 27/49 Loss 0.7970393896102905: \n",
            "Epoch 3/10 Iteration 28/49 Loss 0.7442444562911987: \n",
            "Epoch 3/10 Iteration 29/49 Loss 0.8287700414657593: \n",
            "Epoch 3/10 Iteration 30/49 Loss 0.7616159915924072: \n",
            "Epoch 3/10 Iteration 31/49 Loss 0.7459707260131836: \n",
            "Epoch 3/10 Iteration 32/49 Loss 0.7603310346603394: \n",
            "Epoch 3/10 Iteration 33/49 Loss 0.8041214942932129: \n",
            "Epoch 3/10 Iteration 34/49 Loss 0.7640331983566284: \n",
            "Epoch 3/10 Iteration 35/49 Loss 0.7334734797477722: \n",
            "Epoch 3/10 Iteration 36/49 Loss 0.7336338758468628: \n",
            "Epoch 3/10 Iteration 37/49 Loss 0.7716084122657776: \n",
            "Epoch 3/10 Iteration 38/49 Loss 0.7650295495986938: \n",
            "Epoch 3/10 Iteration 39/49 Loss 0.7618918418884277: \n",
            "Epoch 3/10 Iteration 40/49 Loss 0.7218319177627563: \n",
            "Epoch 3/10 Iteration 41/49 Loss 0.7082711458206177: \n",
            "Epoch 3/10 Iteration 42/49 Loss 0.7391215562820435: \n",
            "Epoch 3/10 Iteration 43/49 Loss 0.7349976301193237: \n",
            "Epoch 3/10 Iteration 44/49 Loss 0.7606860995292664: \n",
            "Epoch 3/10 Iteration 45/49 Loss 0.79170823097229: \n",
            "Epoch 3/10 Iteration 46/49 Loss 0.7928756475448608: \n",
            "Epoch 3/10 Iteration 47/49 Loss 0.7223086357116699: \n",
            "Epoch 3/10 Iteration 48/49 Loss 0.7546355128288269: \n",
            "Epoch 3/10 Accuracy 0.7449156045913696 Precision 0.7367854714393616: Recall 0.7449156045913696 F1 0.7373588681221008 ROC_AUC 0.9621435403823853\n",
            "Epoch 4/10 Iteration 0/49 Loss 0.7700250744819641: \n",
            "Epoch 4/10 Iteration 1/49 Loss 0.7627577185630798: \n",
            "Epoch 4/10 Iteration 2/49 Loss 0.7269411087036133: \n",
            "Epoch 4/10 Iteration 3/49 Loss 0.7643855810165405: \n",
            "Epoch 4/10 Iteration 4/49 Loss 0.7739043235778809: \n",
            "Epoch 4/10 Iteration 5/49 Loss 0.7500103712081909: \n",
            "Epoch 4/10 Iteration 6/49 Loss 0.7294996976852417: \n",
            "Epoch 4/10 Iteration 7/49 Loss 0.7481479644775391: \n",
            "Epoch 4/10 Iteration 8/49 Loss 0.7712903022766113: \n",
            "Epoch 4/10 Iteration 9/49 Loss 0.7355632781982422: \n",
            "Epoch 4/10 Iteration 10/49 Loss 0.7500994205474854: \n",
            "Epoch 4/10 Iteration 11/49 Loss 0.7185809016227722: \n",
            "Epoch 4/10 Iteration 12/49 Loss 0.7264189124107361: \n",
            "Epoch 4/10 Iteration 13/49 Loss 0.7471710443496704: \n",
            "Epoch 4/10 Iteration 14/49 Loss 0.7357458472251892: \n",
            "Epoch 4/10 Iteration 15/49 Loss 0.695716142654419: \n",
            "Epoch 4/10 Iteration 16/49 Loss 0.7639745473861694: \n",
            "Epoch 4/10 Iteration 17/49 Loss 0.7080569863319397: \n",
            "Epoch 4/10 Iteration 18/49 Loss 0.7486183643341064: \n",
            "Epoch 4/10 Iteration 19/49 Loss 0.7388944625854492: \n",
            "Epoch 4/10 Iteration 20/49 Loss 0.7460393905639648: \n",
            "Epoch 4/10 Iteration 21/49 Loss 0.706863522529602: \n",
            "Epoch 4/10 Iteration 22/49 Loss 0.7416062355041504: \n",
            "Epoch 4/10 Iteration 23/49 Loss 0.726420521736145: \n",
            "Epoch 4/10 Iteration 24/49 Loss 0.7936228513717651: \n",
            "Epoch 4/10 Iteration 25/49 Loss 0.7408608794212341: \n",
            "Epoch 4/10 Iteration 26/49 Loss 0.7207543849945068: \n",
            "Epoch 4/10 Iteration 27/49 Loss 0.7490844130516052: \n",
            "Epoch 4/10 Iteration 28/49 Loss 0.6966637372970581: \n",
            "Epoch 4/10 Iteration 29/49 Loss 0.7833989262580872: \n",
            "Epoch 4/10 Iteration 30/49 Loss 0.7160959243774414: \n",
            "Epoch 4/10 Iteration 31/49 Loss 0.6997805237770081: \n",
            "Epoch 4/10 Iteration 32/49 Loss 0.7168319225311279: \n",
            "Epoch 4/10 Iteration 33/49 Loss 0.7595482468605042: \n",
            "Epoch 4/10 Iteration 34/49 Loss 0.7191463112831116: \n",
            "Epoch 4/10 Iteration 35/49 Loss 0.6902822256088257: \n",
            "Epoch 4/10 Iteration 36/49 Loss 0.6903363466262817: \n",
            "Epoch 4/10 Iteration 37/49 Loss 0.7293259501457214: \n",
            "Epoch 4/10 Iteration 38/49 Loss 0.7204906344413757: \n",
            "Epoch 4/10 Iteration 39/49 Loss 0.7159477472305298: \n",
            "Epoch 4/10 Iteration 40/49 Loss 0.6775448322296143: \n",
            "Epoch 4/10 Iteration 41/49 Loss 0.6673306822776794: \n",
            "Epoch 4/10 Iteration 42/49 Loss 0.6948552131652832: \n",
            "Epoch 4/10 Iteration 43/49 Loss 0.6916670799255371: \n",
            "Epoch 4/10 Iteration 44/49 Loss 0.7175748348236084: \n",
            "Epoch 4/10 Iteration 45/49 Loss 0.7501528263092041: \n",
            "Epoch 4/10 Iteration 46/49 Loss 0.7506450414657593: \n",
            "Epoch 4/10 Iteration 47/49 Loss 0.6799252033233643: \n",
            "Epoch 4/10 Iteration 48/49 Loss 0.7133810520172119: \n",
            "Epoch 4/10 Accuracy 0.7646613121032715 Precision 0.7566386461257935: Recall 0.7646613121032715 F1 0.7573099136352539 ROC_AUC 0.9652652740478516\n",
            "Epoch 5/10 Iteration 0/49 Loss 0.7293674945831299: \n",
            "Epoch 5/10 Iteration 1/49 Loss 0.7236747741699219: \n",
            "Epoch 5/10 Iteration 2/49 Loss 0.687542200088501: \n",
            "Epoch 5/10 Iteration 3/49 Loss 0.7253419160842896: \n",
            "Epoch 5/10 Iteration 4/49 Loss 0.735161542892456: \n",
            "Epoch 5/10 Iteration 5/49 Loss 0.7122717499732971: \n",
            "Epoch 5/10 Iteration 6/49 Loss 0.6924482583999634: \n",
            "Epoch 5/10 Iteration 7/49 Loss 0.7104901671409607: \n",
            "Epoch 5/10 Iteration 8/49 Loss 0.7288488149642944: \n",
            "Epoch 5/10 Iteration 9/49 Loss 0.6944267153739929: \n",
            "Epoch 5/10 Iteration 10/49 Loss 0.7145198583602905: \n",
            "Epoch 5/10 Iteration 11/49 Loss 0.6817667484283447: \n",
            "Epoch 5/10 Iteration 12/49 Loss 0.6883273720741272: \n",
            "Epoch 5/10 Iteration 13/49 Loss 0.7090193033218384: \n",
            "Epoch 5/10 Iteration 14/49 Loss 0.6970915794372559: \n",
            "Epoch 5/10 Iteration 15/49 Loss 0.6602377891540527: \n",
            "Epoch 5/10 Iteration 16/49 Loss 0.7275436520576477: \n",
            "Epoch 5/10 Iteration 17/49 Loss 0.6719474792480469: \n",
            "Epoch 5/10 Iteration 18/49 Loss 0.7103536128997803: \n",
            "Epoch 5/10 Iteration 19/49 Loss 0.7027027010917664: \n",
            "Epoch 5/10 Iteration 20/49 Loss 0.7108449339866638: \n",
            "Epoch 5/10 Iteration 21/49 Loss 0.6692134141921997: \n",
            "Epoch 5/10 Iteration 22/49 Loss 0.7078902721405029: \n",
            "Epoch 5/10 Iteration 23/49 Loss 0.6910867094993591: \n",
            "Epoch 5/10 Iteration 24/49 Loss 0.7603868842124939: \n",
            "Epoch 5/10 Iteration 25/49 Loss 0.7051048874855042: \n",
            "Epoch 5/10 Iteration 26/49 Loss 0.6865752935409546: \n",
            "Epoch 5/10 Iteration 27/49 Loss 0.7136256098747253: \n",
            "Epoch 5/10 Iteration 28/49 Loss 0.6618093252182007: \n",
            "Epoch 5/10 Iteration 29/49 Loss 0.7493730783462524: \n",
            "Epoch 5/10 Iteration 30/49 Loss 0.6828922033309937: \n",
            "Epoch 5/10 Iteration 31/49 Loss 0.6654877662658691: \n",
            "Epoch 5/10 Iteration 32/49 Loss 0.6852920055389404: \n",
            "Epoch 5/10 Iteration 33/49 Loss 0.7266213297843933: \n",
            "Epoch 5/10 Iteration 34/49 Loss 0.6856033802032471: \n",
            "Epoch 5/10 Iteration 35/49 Loss 0.6583982706069946: \n",
            "Epoch 5/10 Iteration 36/49 Loss 0.6581151485443115: \n",
            "Epoch 5/10 Iteration 37/49 Loss 0.6975760459899902: \n",
            "Epoch 5/10 Iteration 38/49 Loss 0.6873531341552734: \n",
            "Epoch 5/10 Iteration 39/49 Loss 0.682088315486908: \n",
            "Epoch 5/10 Iteration 40/49 Loss 0.6443494558334351: \n",
            "Epoch 5/10 Iteration 41/49 Loss 0.6370648145675659: \n",
            "Epoch 5/10 Iteration 42/49 Loss 0.6617416143417358: \n",
            "Epoch 5/10 Iteration 43/49 Loss 0.6591060161590576: \n",
            "Epoch 5/10 Iteration 44/49 Loss 0.6853189468383789: \n",
            "Epoch 5/10 Iteration 45/49 Loss 0.7188847064971924: \n",
            "Epoch 5/10 Iteration 46/49 Loss 0.7187656164169312: \n",
            "Epoch 5/10 Iteration 47/49 Loss 0.6482622623443604: \n",
            "Epoch 5/10 Iteration 48/49 Loss 0.6819422841072083: \n",
            "Epoch 5/10 Accuracy 0.780227780342102 Precision 0.7734330296516418: Recall 0.780227780342102 F1 0.7738891839981079 ROC_AUC 0.9676735997200012\n",
            "Epoch 6/10 Iteration 0/49 Loss 0.6984384059906006: \n",
            "Epoch 6/10 Iteration 1/49 Loss 0.6944745779037476: \n",
            "Epoch 6/10 Iteration 2/49 Loss 0.6577751636505127: \n",
            "Epoch 6/10 Iteration 3/49 Loss 0.6960123777389526: \n",
            "Epoch 6/10 Iteration 4/49 Loss 0.7061015963554382: \n",
            "Epoch 6/10 Iteration 5/49 Loss 0.6836133003234863: \n",
            "Epoch 6/10 Iteration 6/49 Loss 0.6641751527786255: \n",
            "Epoch 6/10 Iteration 7/49 Loss 0.6818298101425171: \n",
            "Epoch 6/10 Iteration 8/49 Loss 0.6962994337081909: \n",
            "Epoch 6/10 Iteration 9/49 Loss 0.6630215048789978: \n",
            "Epoch 6/10 Iteration 10/49 Loss 0.6872379779815674: \n",
            "Epoch 6/10 Iteration 11/49 Loss 0.6537976861000061: \n",
            "Epoch 6/10 Iteration 12/49 Loss 0.6591577529907227: \n",
            "Epoch 6/10 Iteration 13/49 Loss 0.6794373989105225: \n",
            "Epoch 6/10 Iteration 14/49 Loss 0.667793869972229: \n",
            "Epoch 6/10 Iteration 15/49 Loss 0.6334007978439331: \n",
            "Epoch 6/10 Iteration 16/49 Loss 0.6995232105255127: \n",
            "Epoch 6/10 Iteration 17/49 Loss 0.6443419456481934: \n",
            "Epoch 6/10 Iteration 18/49 Loss 0.6808258891105652: \n",
            "Epoch 6/10 Iteration 19/49 Loss 0.6751381754875183: \n",
            "Epoch 6/10 Iteration 20/49 Loss 0.6837061643600464: \n",
            "Epoch 6/10 Iteration 21/49 Loss 0.6401234269142151: \n",
            "Epoch 6/10 Iteration 22/49 Loss 0.6818721294403076: \n",
            "Epoch 6/10 Iteration 23/49 Loss 0.6635650992393494: \n",
            "Epoch 6/10 Iteration 24/49 Loss 0.7347571849822998: \n",
            "Epoch 6/10 Iteration 25/49 Loss 0.6773338317871094: \n",
            "Epoch 6/10 Iteration 26/49 Loss 0.6601042151451111: \n",
            "Epoch 6/10 Iteration 27/49 Loss 0.6861563324928284: \n",
            "Epoch 6/10 Iteration 28/49 Loss 0.6348230838775635: \n",
            "Epoch 6/10 Iteration 29/49 Loss 0.7224645614624023: \n",
            "Epoch 6/10 Iteration 30/49 Loss 0.6573671102523804: \n",
            "Epoch 6/10 Iteration 31/49 Loss 0.6386865377426147: \n",
            "Epoch 6/10 Iteration 32/49 Loss 0.6610897779464722: \n",
            "Epoch 6/10 Iteration 33/49 Loss 0.7009507417678833: \n",
            "Epoch 6/10 Iteration 34/49 Loss 0.6594299077987671: \n",
            "Epoch 6/10 Iteration 35/49 Loss 0.6336004734039307: \n",
            "Epoch 6/10 Iteration 36/49 Loss 0.6328032612800598: \n",
            "Epoch 6/10 Iteration 37/49 Loss 0.6726489067077637: \n",
            "Epoch 6/10 Iteration 38/49 Loss 0.6612066030502319: \n",
            "Epoch 6/10 Iteration 39/49 Loss 0.6556769609451294: \n",
            "Epoch 6/10 Iteration 40/49 Loss 0.618243932723999: \n",
            "Epoch 6/10 Iteration 41/49 Loss 0.6136447787284851: \n",
            "Epoch 6/10 Iteration 42/49 Loss 0.6358281970024109: \n",
            "Epoch 6/10 Iteration 43/49 Loss 0.633354663848877: \n",
            "Epoch 6/10 Iteration 44/49 Loss 0.6600155234336853: \n",
            "Epoch 6/10 Iteration 45/49 Loss 0.6942897439002991: \n",
            "Epoch 6/10 Iteration 46/49 Loss 0.6934937834739685: \n",
            "Epoch 6/10 Iteration 47/49 Loss 0.6235460042953491: \n",
            "Epoch 6/10 Iteration 48/49 Loss 0.6569123864173889: \n",
            "Epoch 6/10 Accuracy 0.7919216156005859 Precision 0.7857607007026672: Recall 0.7919216156005859 F1 0.786243200302124 ROC_AUC 0.9694342017173767\n",
            "Epoch 7/10 Iteration 0/49 Loss 0.6737995147705078: \n",
            "Epoch 7/10 Iteration 1/49 Loss 0.6716603636741638: \n",
            "Epoch 7/10 Iteration 2/49 Loss 0.6342655420303345: \n",
            "Epoch 7/10 Iteration 3/49 Loss 0.6727762222290039: \n",
            "Epoch 7/10 Iteration 4/49 Loss 0.6831579208374023: \n",
            "Epoch 7/10 Iteration 5/49 Loss 0.6610066890716553: \n",
            "Epoch 7/10 Iteration 6/49 Loss 0.6417045593261719: \n",
            "Epoch 7/10 Iteration 7/49 Loss 0.6590244174003601: \n",
            "Epoch 7/10 Iteration 8/49 Loss 0.6702184677124023: \n",
            "Epoch 7/10 Iteration 9/49 Loss 0.6380079984664917: \n",
            "Epoch 7/10 Iteration 10/49 Loss 0.6654391288757324: \n",
            "Epoch 7/10 Iteration 11/49 Loss 0.6316215991973877: \n",
            "Epoch 7/10 Iteration 12/49 Loss 0.6358349323272705: \n",
            "Epoch 7/10 Iteration 13/49 Loss 0.6557254791259766: \n",
            "Epoch 7/10 Iteration 14/49 Loss 0.6443700194358826: \n",
            "Epoch 7/10 Iteration 15/49 Loss 0.6123925447463989: \n",
            "Epoch 7/10 Iteration 16/49 Loss 0.6770331859588623: \n",
            "Epoch 7/10 Iteration 17/49 Loss 0.622475802898407: \n",
            "Epoch 7/10 Iteration 18/49 Loss 0.6571766138076782: \n",
            "Epoch 7/10 Iteration 19/49 Loss 0.653342604637146: \n",
            "Epoch 7/10 Iteration 20/49 Loss 0.6619548797607422: \n",
            "Epoch 7/10 Iteration 21/49 Loss 0.6166850328445435: \n",
            "Epoch 7/10 Iteration 22/49 Loss 0.6610766649246216: \n",
            "Epoch 7/10 Iteration 23/49 Loss 0.6413260698318481: \n",
            "Epoch 7/10 Iteration 24/49 Loss 0.7142353057861328: \n",
            "Epoch 7/10 Iteration 25/49 Loss 0.6548798084259033: \n",
            "Epoch 7/10 Iteration 26/49 Loss 0.6389907598495483: \n",
            "Epoch 7/10 Iteration 27/49 Loss 0.6640146374702454: \n",
            "Epoch 7/10 Iteration 28/49 Loss 0.6132202744483948: \n",
            "Epoch 7/10 Iteration 29/49 Loss 0.7005835771560669: \n",
            "Epoch 7/10 Iteration 30/49 Loss 0.6368354558944702: \n",
            "Epoch 7/10 Iteration 31/49 Loss 0.6171314716339111: \n",
            "Epoch 7/10 Iteration 32/49 Loss 0.6418439149856567: \n",
            "Epoch 7/10 Iteration 33/49 Loss 0.680229902267456: \n",
            "Epoch 7/10 Iteration 34/49 Loss 0.6382606625556946: \n",
            "Epoch 7/10 Iteration 35/49 Loss 0.6135518550872803: \n",
            "Epoch 7/10 Iteration 36/49 Loss 0.6122503280639648: \n",
            "Epoch 7/10 Iteration 37/49 Loss 0.6524306535720825: \n",
            "Epoch 7/10 Iteration 38/49 Loss 0.6400442123413086: \n",
            "Epoch 7/10 Iteration 39/49 Loss 0.6343953609466553: \n",
            "Epoch 7/10 Iteration 40/49 Loss 0.5971171855926514: \n",
            "Epoch 7/10 Iteration 41/49 Loss 0.594886064529419: \n",
            "Epoch 7/10 Iteration 42/49 Loss 0.6148219108581543: \n",
            "Epoch 7/10 Iteration 43/49 Loss 0.6122996211051941: \n",
            "Epoch 7/10 Iteration 44/49 Loss 0.6395370960235596: \n",
            "Epoch 7/10 Iteration 45/49 Loss 0.6742382049560547: \n",
            "Epoch 7/10 Iteration 46/49 Loss 0.6727913618087769: \n",
            "Epoch 7/10 Iteration 47/49 Loss 0.6035959720611572: \n",
            "Epoch 7/10 Iteration 48/49 Loss 0.6363239288330078: \n",
            "Epoch 7/10 Accuracy 0.8035210371017456 Precision 0.7974690198898315: Recall 0.8035210371017456 F1 0.7979442477226257 ROC_AUC 0.9708511233329773\n",
            "Epoch 8/10 Iteration 0/49 Loss 0.6536480188369751: \n",
            "Epoch 8/10 Iteration 1/49 Loss 0.6532256007194519: \n",
            "Epoch 8/10 Iteration 2/49 Loss 0.6152045130729675: \n",
            "Epoch 8/10 Iteration 3/49 Loss 0.6539421081542969: \n",
            "Epoch 8/10 Iteration 4/49 Loss 0.6645970344543457: \n",
            "Epoch 8/10 Iteration 5/49 Loss 0.6426739692687988: \n",
            "Epoch 8/10 Iteration 6/49 Loss 0.6232149600982666: \n",
            "Epoch 8/10 Iteration 7/49 Loss 0.6402162909507751: \n",
            "Epoch 8/10 Iteration 8/49 Loss 0.6485671997070312: \n",
            "Epoch 8/10 Iteration 9/49 Loss 0.6176321506500244: \n",
            "Epoch 8/10 Iteration 10/49 Loss 0.6475808024406433: \n",
            "Epoch 8/10 Iteration 11/49 Loss 0.6134430766105652: \n",
            "Epoch 8/10 Iteration 12/49 Loss 0.6165964603424072: \n",
            "Epoch 8/10 Iteration 13/49 Loss 0.6360574960708618: \n",
            "Epoch 8/10 Iteration 14/49 Loss 0.625193178653717: \n",
            "Epoch 8/10 Iteration 15/49 Loss 0.5953779816627502: \n",
            "Epoch 8/10 Iteration 16/49 Loss 0.6585412621498108: \n",
            "Epoch 8/10 Iteration 17/49 Loss 0.6045749187469482: \n",
            "Epoch 8/10 Iteration 18/49 Loss 0.6375919580459595: \n",
            "Epoch 8/10 Iteration 19/49 Loss 0.635568380355835: \n",
            "Epoch 8/10 Iteration 20/49 Loss 0.644147515296936: \n",
            "Epoch 8/10 Iteration 21/49 Loss 0.5972921252250671: \n",
            "Epoch 8/10 Iteration 22/49 Loss 0.6439478397369385: \n",
            "Epoch 8/10 Iteration 23/49 Loss 0.6227911710739136: \n",
            "Epoch 8/10 Iteration 24/49 Loss 0.6973186135292053: \n",
            "Epoch 8/10 Iteration 25/49 Loss 0.6362622976303101: \n",
            "Epoch 8/10 Iteration 26/49 Loss 0.621576189994812: \n",
            "Epoch 8/10 Iteration 27/49 Loss 0.6457095742225647: \n",
            "Epoch 8/10 Iteration 28/49 Loss 0.5952078104019165: \n",
            "Epoch 8/10 Iteration 29/49 Loss 0.6822270154953003: \n",
            "Epoch 8/10 Iteration 30/49 Loss 0.6198064684867859: \n",
            "Epoch 8/10 Iteration 31/49 Loss 0.5993174314498901: \n",
            "Epoch 8/10 Iteration 32/49 Loss 0.6260509490966797: \n",
            "Epoch 8/10 Iteration 33/49 Loss 0.6628459692001343: \n",
            "Epoch 8/10 Iteration 34/49 Loss 0.6205950975418091: \n",
            "Epoch 8/10 Iteration 35/49 Loss 0.5969270467758179: \n",
            "Epoch 8/10 Iteration 36/49 Loss 0.5951381921768188: \n",
            "Epoch 8/10 Iteration 37/49 Loss 0.6354727745056152: \n",
            "Epoch 8/10 Iteration 38/49 Loss 0.6223828196525574: \n",
            "Epoch 8/10 Iteration 39/49 Loss 0.6167888045310974: \n",
            "Epoch 8/10 Iteration 40/49 Loss 0.5793774127960205: \n",
            "Epoch 8/10 Iteration 41/49 Loss 0.5793982744216919: \n",
            "Epoch 8/10 Iteration 42/49 Loss 0.5973172187805176: \n",
            "Epoch 8/10 Iteration 43/49 Loss 0.5946990251541138: \n",
            "Epoch 8/10 Iteration 44/49 Loss 0.6224925518035889: \n",
            "Epoch 8/10 Iteration 45/49 Loss 0.6573423147201538: \n",
            "Epoch 8/10 Iteration 46/49 Loss 0.6554687023162842: \n",
            "Epoch 8/10 Iteration 47/49 Loss 0.5869882106781006: \n",
            "Epoch 8/10 Iteration 48/49 Loss 0.6188294291496277: \n",
            "Epoch 8/10 Accuracy 0.8125654458999634 Precision 0.8068997263908386: Recall 0.8125654458999634 F1 0.8073662519454956 ROC_AUC 0.9719806909561157\n",
            "Epoch 9/10 Iteration 0/49 Loss 0.6367919445037842: \n",
            "Epoch 9/10 Iteration 1/49 Loss 0.6377806067466736: \n",
            "Epoch 9/10 Iteration 2/49 Loss 0.5994069576263428: \n",
            "Epoch 9/10 Iteration 3/49 Loss 0.6382163763046265: \n",
            "Epoch 9/10 Iteration 4/49 Loss 0.6491648554801941: \n",
            "Epoch 9/10 Iteration 5/49 Loss 0.6273080706596375: \n",
            "Epoch 9/10 Iteration 6/49 Loss 0.6076955795288086: \n",
            "Epoch 9/10 Iteration 7/49 Loss 0.6242833733558655: \n",
            "Epoch 9/10 Iteration 8/49 Loss 0.6302528381347656: \n",
            "Epoch 9/10 Iteration 9/49 Loss 0.6005263924598694: \n",
            "Epoch 9/10 Iteration 10/49 Loss 0.6326327919960022: \n",
            "Epoch 9/10 Iteration 11/49 Loss 0.5981958508491516: \n",
            "Epoch 9/10 Iteration 12/49 Loss 0.6002964377403259: \n",
            "Epoch 9/10 Iteration 13/49 Loss 0.6192893981933594: \n",
            "Epoch 9/10 Iteration 14/49 Loss 0.6090543270111084: \n",
            "Epoch 9/10 Iteration 15/49 Loss 0.5812028646469116: \n",
            "Epoch 9/10 Iteration 16/49 Loss 0.6430000066757202: \n",
            "Epoch 9/10 Iteration 17/49 Loss 0.5894523859024048: \n",
            "Epoch 9/10 Iteration 18/49 Loss 0.6209673881530762: \n",
            "Epoch 9/10 Iteration 19/49 Loss 0.620619535446167: \n",
            "Epoch 9/10 Iteration 20/49 Loss 0.6292206048965454: \n",
            "Epoch 9/10 Iteration 21/49 Loss 0.5809401869773865: \n",
            "Epoch 9/10 Iteration 22/49 Loss 0.6294883489608765: \n",
            "Epoch 9/10 Iteration 23/49 Loss 0.6070551872253418: \n",
            "Epoch 9/10 Iteration 24/49 Loss 0.6830211281776428: \n",
            "Epoch 9/10 Iteration 25/49 Loss 0.6204231977462769: \n",
            "Epoch 9/10 Iteration 26/49 Loss 0.6069451570510864: \n",
            "Epoch 9/10 Iteration 27/49 Loss 0.6302124261856079: \n",
            "Epoch 9/10 Iteration 28/49 Loss 0.5799518823623657: \n",
            "Epoch 9/10 Iteration 29/49 Loss 0.6665282249450684: \n",
            "Epoch 9/10 Iteration 30/49 Loss 0.6053579449653625: \n",
            "Epoch 9/10 Iteration 31/49 Loss 0.584257960319519: \n",
            "Epoch 9/10 Iteration 32/49 Loss 0.6128131747245789: \n",
            "Epoch 9/10 Iteration 33/49 Loss 0.6480516791343689: \n",
            "Epoch 9/10 Iteration 34/49 Loss 0.6055376529693604: \n",
            "Epoch 9/10 Iteration 35/49 Loss 0.582840085029602: \n",
            "Epoch 9/10 Iteration 36/49 Loss 0.5805472135543823: \n",
            "Epoch 9/10 Iteration 37/49 Loss 0.6210415363311768: \n",
            "Epoch 9/10 Iteration 38/49 Loss 0.6073557138442993: \n",
            "Epoch 9/10 Iteration 39/49 Loss 0.6019057035446167: \n",
            "Epoch 9/10 Iteration 40/49 Loss 0.5642386078834534: \n",
            "Epoch 9/10 Iteration 41/49 Loss 0.5663822293281555: \n",
            "Epoch 9/10 Iteration 42/49 Loss 0.5824779868125916: \n",
            "Epoch 9/10 Iteration 43/49 Loss 0.5796161890029907: \n",
            "Epoch 9/10 Iteration 44/49 Loss 0.6080251932144165: \n",
            "Epoch 9/10 Iteration 45/49 Loss 0.6428557634353638: \n",
            "Epoch 9/10 Iteration 46/49 Loss 0.6406799554824829: \n",
            "Epoch 9/10 Iteration 47/49 Loss 0.5728816390037537: \n",
            "Epoch 9/10 Iteration 48/49 Loss 0.6038002371788025: \n",
            "Epoch 9/10 Accuracy 0.816530168056488 Precision 0.8112764358520508: Recall 0.816530168056488 F1 0.8113192319869995 ROC_AUC 0.972874641418457\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "'''\n",
        "      In this implementaion we are training the model on the train_loader and also validating the data on he validation_load.\n",
        "      The below plot shows the Training and Validation loss while training the model on the 10 epochs with batch_size = 1024 (pre-defined)\n",
        "\n",
        "      training_loss   : stores the mean training loss over each batch run for all the 10 epoch runs.\n",
        "      validation_loss  : stores the mean validation loss over each batch run for all the 10 epoch runs.\n",
        "\n",
        "      The plot shows that as the model is trained further the testing loss and training loss converges. Leading to better performance of the model. \n",
        "'''\n",
        "from torch.utils.data import DataLoader\n",
        "from torchmetrics.classification import MulticlassAccuracy, MulticlassPrecision, MulticlassRecall, MulticlassF1Score, AUROC, ROC\n",
        "\n",
        "batch_size = 1024\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
        "valid_loader = DataLoader(val_data, batch_size=batch_size)\n",
        "max_epochs = 10\n",
        "learning_rate = 0.01\n",
        "# Storing value of training loss and validation loss for each epoch:\n",
        "# --------------\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "# --------------\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "  loss_per_epoch = 0\n",
        "  for idx, data in enumerate(train_loader):\n",
        "    features, labels = data\n",
        "\n",
        "    features = features.cuda()\n",
        "\n",
        "    labels = labels.cuda()\n",
        "    probs = model(features.reshape([-1, 784]))\n",
        "\n",
        "    loss = ce_loss(probs, labels)\n",
        "    # Recording training_loss:\n",
        "    # --------------\n",
        "    loss_per_epoch = loss_per_epoch + loss.item()\n",
        "    # --------------\n",
        "    #print(\"Epoch {0}/{1} Iteration {2}/{3} Loss {4}: \".format(epoch, max_epochs, idx, len(train_loader), loss))\n",
        "\n",
        "    for param in model.parameters():\n",
        "      param.grad = None\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "      # Write paramtere update routine here:\n",
        "      # --------------\n",
        "      new_param = param - learning_rate * param.grad    \n",
        "      # --------------\n",
        "      with torch.no_grad():\n",
        "        param.copy_(new_param)\n",
        "        \n",
        "  avg_loss_per_iter = loss_per_epoch/len(train_loader);\n",
        "  training_loss.append(avg_loss_per_iter)\n",
        "  loss_per_epoch_valid = 0\n",
        "\n",
        "  # Write Validation routine here: \n",
        "  #----------------------------\n",
        "  for idx, data in enumerate(valid_loader):\n",
        "    features, labels = data\n",
        "    features = features.cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "    accuracy_lst = []\n",
        "    precision_lst = []\n",
        "    recall_lst = []\n",
        "    f1_lst = []\n",
        "    roc_auc_lst = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "      probs = model(features.reshape([-1, 784]))\n",
        "\n",
        "      vloss = ce_loss(probs, labels)\n",
        "      loss_per_epoch_valid = loss_per_epoch_valid + vloss.item()\n",
        "\n",
        "      predicts = torch.argmax(probs, dim=1)\n",
        "\n",
        "      accuracy_matrix = MulticlassAccuracy(task=\"multiclass\", num_classes=10).to(device)\n",
        "      accuracy_lst.append(accuracy_matrix(predicts, labels).item())\n",
        "\n",
        "      precision_matrix = MulticlassPrecision(task=\"multiclass\", num_classes=10).to(device)\n",
        "      precision_lst.append(precision_matrix(predicts, labels).item())\n",
        "\n",
        "      recall_matrix = MulticlassRecall(task=\"multiclass\", num_classes=10).to(device)\n",
        "      recall_lst.append(recall_matrix(predicts, labels).item())\n",
        "\n",
        "      f1_matrix = MulticlassF1Score(task=\"multiclass\", num_classes=10).to(device)\n",
        "      f1_lst.append(f1_matrix(predicts, labels).item())\n",
        "\n",
        "      roc_auc_matrix = AUROC(task=\"multiclass\", num_classes=10).to(device)\n",
        "      roc_auc_lst.append(roc_auc_matrix(probs, labels).item())\n",
        "\n",
        "  print(\"Epoch {0}/{1} Accuracy {2} Precision {3}: Recall {4} F1 {5} ROC_AUC {6}\".format(epoch , len(valid_loader), sum(accuracy_lst)/len(accuracy_lst), sum(precision_lst)/len(precision_lst), sum(recall_lst)/len(recall_lst), sum(f1_lst)/len(f1_lst), sum(roc_auc_lst)/len(roc_auc_lst)))\n",
        "  avg_valid_loss_per_iter = loss_per_epoch_valid/len(valid_loader)\n",
        "  validation_loss.append(avg_valid_loss_per_iter)\n",
        "\n",
        "plt.plot(training_loss, label='Training Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(training_loss, label='Training Loss')\n",
        "plt.plot(validation_loss, label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXV_Q44g9ese"
      },
      "source": [
        "Testing the Neural Network\n",
        "  + Change the *seed* and train the neural network 10 times\n",
        "  + Report the mean and variance over 10 trials on the following metrics:\n",
        "    + Accuracy\n",
        "    + Precision\n",
        "    + Recall\n",
        "    + F1\n",
        "    + ROC curve\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCBNOBOK9o1w",
        "outputId": "c6d0b167-5a42-4758-a668-44afbe47a8e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed: 1898\n",
            "Seed: 2287\n",
            "Seed: 1658\n",
            "Seed: 2871\n",
            "Seed: 1259\n",
            "Seed: 2603\n",
            "Seed: 2250\n",
            "Seed: 2958\n",
            "Seed: 2532\n",
            "Seed: 2015\n",
            "Accuracy_PostTrials [0.7797717787742615, 0.7816561443328858, 0.7828337652206421, 0.7740308387756347, 0.7818683427810669, 0.7924730932235717, 0.7874010787963868, 0.7901204986572266, 0.788714882850647, 0.7892341684341431] precision_postTrials [0.7773196880340576, 0.7797733465194702, 0.780192604637146, 0.7715264959335327, 0.7802674278259277, 0.790047458076477, 0.7840385536193848, 0.7879504689216614, 0.7870594895362854, 0.7857215991973877] recall_postTrials [0.7797717787742615, 0.7816561443328858, 0.7828337652206421, 0.7740308387756347, 0.7818683427810669, 0.7924730932235717, 0.7874010787963868, 0.7901204986572266, 0.788714882850647, 0.7892341684341431] f1_postTrials [0.7766911413192749, 0.7793644353866577, 0.7799691547393799, 0.7713239065170288, 0.7793094509124756, 0.7895264785766601, 0.784501943397522, 0.7875038537979125, 0.78721320810318, 0.7860152760505676] roc_auc_postTrials [0.9711518301963806, 0.971226551246643, 0.9715409169197082, 0.9709267508506775, 0.9718771982192993, 0.972341053199768, 0.9717777844429016, 0.9727744633674622, 0.9729006304740906, 0.9718879963874817]\n",
            "Mean: Accuracy 0.7848104591846468 Precision 0.7823897132301331: Recall 0.7848104591846468 F1 0.782141884880066 roc_auc 0.9718405175304413\n",
            "Variance: Accuracy 2.9253910385925587e-05 Precision 2.850814112630324e-05: Recall 2.9253910385925587e-05 F1 2.9677121470064998e-05 roc_auc 4.0301403038579086e-07\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "      In this implementaion we are training the model 10 times on the the train_loader, by chaingng the seed value and then test it on the test_load\n",
        "      \n",
        "      accuracy_postTrials   : stores the mean accuracy score on test_load for each trail.\n",
        "      precision_postTrials  : stores the mean precision score on test_load for each trail.\n",
        "      recall_postTrials : stores the mean recall score on test_load for each trail.\n",
        "      f1_postTrials: stores the mean F1 score on test_load for each trail.\n",
        "      roc_auc_postTrials: stores the mean roc_auc score on test_load for each trail.\n",
        "\n",
        "'''\n",
        "#----------------------------------------------------\n",
        "\n",
        "accuracy_postTrials = []\n",
        "precision_postTrials = []\n",
        "recall_postTrials = []\n",
        "f1_postTrials= []\n",
        "roc_auc_postTrials = []\n",
        "\n",
        "for iter in range(0,10):\n",
        "  seed = random.randrange(1024,3456) ## change this seed when you run trials\n",
        "  random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  print(f\"Seed: {seed}\")\n",
        "  model = NeuralNetwork().cuda()\n",
        "\n",
        "  for epoch in range(max_epochs):\n",
        "    for idx, data in enumerate(train_loader):\n",
        "      features, labels = data\n",
        "      features = features.cuda()\n",
        "      labels = labels.cuda()\n",
        "      probs = model(features.reshape([-1, 784]))\n",
        "      #print(\"Epoch {0}/{1} Iteration {2}/{3} Loss {4}: \".format(epoch, max_epochs, idx, len(train_loader), loss))\n",
        "      loss = ce_loss(probs, labels)\n",
        "      for param in model.parameters():\n",
        "        param.grad = None\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      for name, param in model.named_parameters():\n",
        "        new_param = param - learning_rate * param.grad    \n",
        "\n",
        "        with torch.no_grad():\n",
        "          param.copy_(new_param)\n",
        "\n",
        "  accuracy_lst = []\n",
        "  precision_lst = []\n",
        "  recall_lst = []\n",
        "  f1_lst = []\n",
        "  roc_auc_lst = []\n",
        "\n",
        "  for idx, data in enumerate(test_loader):\n",
        "    features, labels = data\n",
        "    features = features.cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "  \n",
        "    with torch.no_grad():\n",
        "      probs = model(features.reshape([-1, 784]))\n",
        "      predicts = torch.argmax(probs, dim=1)\n",
        "\n",
        "      accuracy_matrix = MulticlassAccuracy(task=\"multiclass\", num_classes=10).to(device)\n",
        "      accuracy_lst.append(accuracy_matrix(predicts, labels).item()*labels.size()[0])\n",
        "\n",
        "      precision_matrix = MulticlassPrecision(task=\"multiclass\", num_classes=10).to(device)\n",
        "      precision_lst.append(precision_matrix(predicts, labels).item()*labels.size()[0])\n",
        "\n",
        "      recall_matrix = MulticlassRecall(task=\"multiclass\", num_classes=10).to(device)\n",
        "      recall_lst.append(recall_matrix(predicts, labels).item()*labels.size()[0])\n",
        "\n",
        "      f1_matrix = MulticlassF1Score(task=\"multiclass\", num_classes=10).to(device)\n",
        "      f1_lst.append(f1_matrix(predicts, labels).item()*labels.size()[0])\n",
        "\n",
        "      roc_auc_matrix = AUROC(task=\"multiclass\", num_classes=10).to(device)\n",
        "      roc_auc_lst.append(roc_auc_matrix(probs, labels).item()*labels.size()[0])\n",
        "\n",
        "  #Weighted_Average as last batch_size if not same as all.\n",
        "  accuracy_postTrials.append(sum(accuracy_lst)/len(test_loader.dataset))\n",
        "  precision_postTrials.append(sum(precision_lst)/len(test_loader.dataset))\n",
        "  recall_postTrials.append(sum(recall_lst)/len(test_loader.dataset))\n",
        "  f1_postTrials.append(sum(f1_lst)/len(test_loader.dataset))\n",
        "  roc_auc_postTrials.append(sum(roc_auc_lst)/len(test_loader.dataset))\n",
        "  \n",
        "print(f\"Accuracy_PostTrials {accuracy_postTrials} precision_postTrials {precision_postTrials} recall_postTrials {recall_postTrials} f1_postTrials {f1_postTrials} roc_auc_postTrials {roc_auc_postTrials}\")\n",
        "print(\"Mean: Accuracy {2} Precision {3}: Recall {4} F1 {5} roc_auc {6}\".format(epoch , len(valid_loader), sum(accuracy_postTrials)/len(accuracy_postTrials), sum(precision_postTrials)/len(precision_postTrials), sum(recall_postTrials)/len(recall_postTrials), sum(f1_postTrials)/len(f1_postTrials), sum(roc_auc_postTrials)/len(roc_auc_postTrials)))\n",
        "print(\"Variance: Accuracy {2} Precision {3}: Recall {4} F1 {5} roc_auc {6}\".format(epoch , len(valid_loader), np.var(accuracy_postTrials), np.var(precision_postTrials), np.var(recall_postTrials), np.var(f1_postTrials), np.var(roc_auc_postTrials)))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W6ZCfma9iTr"
      },
      "source": [
        "+ Change the number of parameters in the Neural Network \n",
        "  + Train an underfit model\n",
        "  + Train a overfit model\n",
        "  + Demostrate the difference between overfitting and underfitting. Give detailed reasoning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "BsBJEuAn9hVr"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "      Below is the implmentation of the UnderfirNeuralNetwork in which the number of neurons per network are decreased.\n",
        "\n",
        "'''\n",
        "class UnderfitNeuralNetwork(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(UnderfitNeuralNetwork, self).__init__()\n",
        "\n",
        "    #reducing the number of neurons in the layers for underfiting\n",
        "    self.layer_1 = CustomLinearLayer(784,5)\n",
        "    self.layer_2 = CustomLinearLayer(5,10)\n",
        "    self.activation = torch.nn.ReLU()\n",
        "    self.softmax = torch.nn.Softmax(dim=-1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    # Apply layers defined above:\n",
        "    #-------------------------------\n",
        "    output = self.layer_1(x) #Apply layer_1 on input\n",
        "    output = self.activation(output) #Apply activation function on the result\n",
        "    output = self.layer_2(output) #Apply layer_2 on the result (: output)\n",
        "    output = self.softmax(output) #Apply Softmax and return the final result\n",
        "    #-------------------------------\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "EioMZNmZEC6v",
        "outputId": "7232d167-6dcb-42cc-adf7-66515794fa03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training_Loss [2.2563399052133364, 2.20307656210296, 2.1636683697603187, 2.1270131529593956, 2.0881856023048866, 2.038044168024647, 1.9616913917113323, 1.8480031028085826, 1.7027479653455773, 1.555671475371536, 1.4330494306525405, 1.3411138763233108, 1.271401312886452, 1.2152069393469362, 1.1679171080491981, 1.1271931808822009, 1.0917371341160365, 1.060752382083815, 1.033623154066047, 1.0098324442396358, 0.9889035906110492, 0.9704114952865912, 0.953987297963123, 0.9393094924031472, 0.9260987323157641, 0.9141333309971557, 0.9032168753293096, 0.8931834478767551, 0.8838934192852098, 0.8752353337346291, 0.8671141923690329, 0.8594607747330958, 0.8522075037566983, 0.845298344991645, 0.8386973276430246, 0.8323647233904624, 0.8262723331548729, 0.8203967700199205, 0.8147240305433467, 0.8092390092051759, 0.8039294262321628, 0.7987839457940082, 0.7937903611027465, 0.7889419392663606, 0.784229406288692, 0.7796474634384623, 0.7751928129974677, 0.7708601927270695, 0.7666444790606596, 0.7625412880157938, 0.7585461066693676, 0.7546544318296471, 0.7508613187439588, 0.7471630719243264, 0.7435574385584617, 0.7400402694332356, 0.7366087375854959, 0.7332561271531242, 0.7299832020487104, 0.7267856354616127, 0.7236594448284227, 0.7206033261454835, 0.7176119393231918, 0.7146846262776122, 0.7118185369335875, 0.709012179958577, 0.7062631298084648, 0.7035687967222564, 0.7009291940805863, 0.6983408940081693]\n",
            "Testing_Loss [2.22728545665741, 2.1845089197158813, 2.1474318981170653, 2.1108510494232178, 2.0688018560409547, 2.007806491851807, 1.9142137050628663, 1.7819138526916505, 1.6310287237167358, 1.4947705149650574, 1.3896381735801697, 1.3120871424674987, 1.2515028715133667, 1.2014904499053956, 1.158861243724823, 1.1219185948371888, 1.0897221088409423, 1.0615887880325316, 1.036984145641327, 1.0154169976711274, 0.9964308857917785, 0.979638522863388, 0.9646930932998657, 0.9513063848018646, 0.9392393231391907, 0.9282742083072663, 0.9182375788688659, 0.9089854419231415, 0.9003923237323761, 0.8923631727695465, 0.8848228037357331, 0.8777033030986786, 0.870944082736969, 0.864500629901886, 0.8583377063274383, 0.8524161875247955, 0.8467161417007446, 0.8412216961383819, 0.835919713973999, 0.8307940125465393, 0.8258340060710907, 0.8210276246070862, 0.8163648307323456, 0.8118399143218994, 0.8074444174766541, 0.803172355890274, 0.7990173876285553, 0.7949805438518525, 0.7910527110099792, 0.7872264742851257, 0.7834994733333588, 0.7798703610897064, 0.7763297498226166, 0.772876751422882, 0.76950643658638, 0.7662170648574829, 0.763001412153244, 0.7598593652248382, 0.7567884624004364, 0.7537863492965698, 0.7508487403392792, 0.7479725241661072, 0.7451521933078766, 0.742385059595108, 0.7396746039390564, 0.7370194315910339, 0.7344113707542419, 0.7318520069122314, 0.7293412327766419, 0.7268737554550171]\n",
            "Validation_Loss [2.225402593612671, 2.1831705570220947, 2.1465160846710205, 2.110275888442993, 2.068435049057007, 2.0077819347381594, 1.914550745487213, 1.7825072288513184, 1.6317860960960389, 1.4955891251564026, 1.3901840090751647, 1.3118738770484923, 1.2502430438995362, 1.199135148525238, 1.1554577469825744, 1.1175545811653138, 1.0844735980033875, 1.055516493320465, 1.0301100850105285, 1.0077762305736542, 0.9880657732486725, 0.9705832064151764, 0.954984474182129, 0.940972912311554, 0.9282916128635407, 0.9167385995388031, 0.9061408400535583, 0.8963501930236817, 0.8872323393821716, 0.8787023007869721, 0.8706790089607239, 0.8630913078784943, 0.8558814585208893, 0.8490036070346832, 0.8424153566360474, 0.8360856115818024, 0.8299900472164154, 0.8241170048713684, 0.8184499084949494, 0.8129746615886688, 0.8076768815517426, 0.8025401830673218, 0.7975633203983307, 0.7927314043045044, 0.7880448341369629, 0.7834884643554687, 0.7790612041950226, 0.7747628629207611, 0.7705864012241364, 0.766527634859085, 0.7625787794589997, 0.7587336421012878, 0.7549922466278076, 0.7513515949249268, 0.7478065192699432, 0.744353461265564, 0.7409836530685425, 0.7376955509185791, 0.7344898223876953, 0.7313576519489289, 0.7282988011837006, 0.7253098666667939, 0.7223853588104248, 0.7195222496986389, 0.7167214334011078, 0.7139906048774719, 0.7113163590431213, 0.7086988151073456, 0.706137478351593, 0.7036247253417969]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Training and Testing UnderFitting Model\n",
        "training_loss = []\n",
        "testing_loss = []\n",
        "validation_loss = []\n",
        "#---------------------\n",
        "model_underfit = UnderfitNeuralNetwork().cuda()\n",
        "\n",
        "for epoch in range(70):\n",
        "  loss_per_epoch = 0\n",
        "  for idx, data in enumerate(train_loader):\n",
        "    features, labels = data\n",
        "    features = features.cuda()\n",
        "    labels = labels.cuda()\n",
        "    probs = model_underfit(features.reshape([-1, 784]))\n",
        "    loss = ce_loss(probs, labels)\n",
        "    loss_per_epoch = loss_per_epoch + loss.item()\n",
        "\n",
        "    for param in model_underfit.parameters():\n",
        "      param.grad = None\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    for name, param in model_underfit.named_parameters():\n",
        "      new_param = param - learning_rate * param.grad    \n",
        "      with torch.no_grad():\n",
        "        param.copy_(new_param)\n",
        "        \n",
        "  avg_loss_per_iter = loss_per_epoch/len(train_loader);\n",
        "  training_loss.append(avg_loss_per_iter)\n",
        "  \n",
        "  testing_loss_per_epoch = 0\n",
        "  for idx, data in enumerate(test_loader):\n",
        "    features, labels = data\n",
        "    features = features.cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      probs = model_underfit(features.reshape([-1, 784]))\n",
        "      predicts = torch.argmax(probs, dim=1)\n",
        "      tloss = ce_loss(probs, labels)\n",
        "      testing_loss_per_epoch = testing_loss_per_epoch + tloss.item()\n",
        "\n",
        "  avg_loss_per_iter = testing_loss_per_epoch/len(test_loader);\n",
        "  testing_loss.append(avg_loss_per_iter)\n",
        "\n",
        "  validation_loss_per_epoch = 0\n",
        "  for idx, data in enumerate(valid_loader):\n",
        "    features, labels = data\n",
        "    features = features.cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      probs = model_underfit(features.reshape([-1, 784]))\n",
        "      predicts = torch.argmax(probs, dim=1)\n",
        "      vloss = ce_loss(probs, labels)\n",
        "      validation_loss_per_epoch = validation_loss_per_epoch + vloss.item()\n",
        "\n",
        "  avg_loss_per_iter = validation_loss_per_epoch/len(valid_loader);\n",
        "  validation_loss.append(avg_loss_per_iter)\n",
        "\n",
        "print(f\"Training_Loss {training_loss}\")\n",
        "print(f\"Testing_Loss {testing_loss}\")\n",
        "print(f\"Validation_Loss {validation_loss}\")\n",
        "plt.plot(training_loss, label='Training Loss')\n",
        "plt.plot(validation_loss, label='Validation Loss')\n",
        "plt.plot(testing_loss, label='Testing Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "h_7hrsuA8ejx"
      },
      "outputs": [],
      "source": [
        "## Create new models for Overfitting Neural Network\n",
        "'''\n",
        "      Below is the implmentation of the OverfitNeuralNetwork in which the number of layers per network are increased.\n",
        "\n",
        "'''\n",
        "#----------------------------------------------------\n",
        "class OverfitNeuralNetwork(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(OverfitNeuralNetwork, self).__init__()\n",
        "\n",
        "    #increasing the number of neurons in the hidden layers for overfitting \n",
        "    self.layer_1 = CustomLinearLayer(784,512)\n",
        "    self.layer_2 = CustomLinearLayer(512,256)\n",
        "    # adding 2 new layer_3 \n",
        "    self.layer_3 = CustomLinearLayer(256,132)\n",
        "    self.layer_4 = CustomLinearLayer(132,10)\n",
        "    self.activation = torch.nn.ReLU()\n",
        "    self.softmax = torch.nn.Softmax(dim=-1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    # Apply layers defined above:\n",
        "    #-------------------------------\n",
        "    output = self.layer_1(x) #Apply layer_1 on input\n",
        "    output = self.activation(output) #Apply activation function on the result\n",
        "    output = self.layer_2(output) #Apply layer_2 on the result (: output)\n",
        "    output = self.activation(output)  #Apply activation function on the result\n",
        "    output = self.layer_3(output)  #Apply layer_3 on the result (: output)\n",
        "    output = self.activation(output)  #Apply activation function on the result\n",
        "    output = self.layer_4(output)  #Apply layer_4 on the result (: output)\n",
        "    output = self.softmax(output) #Apply Softmax and return the final result\n",
        "    #-------------------------------\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "djkO8QfKNvRP",
        "outputId": "be4f3a36-209f-4c0c-d6ca-9f7d4f1c9309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training_Loss [1.4362796885626656, 0.872148047904579, 0.7474829810006278, 0.6813509293964931, 0.6385035539159969, 0.6080628086109551, 0.5851295201145873, 0.5669914593501967, 0.5521129740744221, 0.5395860842296055, 0.5287674148471988, 0.5193745572956241, 0.5109985330883338, 0.5034304036169636, 0.49652160187156835, 0.490219280427816, 0.4843932572676211, 0.4790645795209067, 0.4740729252902829, 0.4693907773008152, 0.46501308618759624, 0.4609315085167788, 0.45702662516613396, 0.45330183238399274, 0.44982110115946555]\n",
            "Testing_Loss [1.0016051173210143, 0.8209423840045929, 0.7371281206607818, 0.686236995458603, 0.6511499583721161, 0.625330924987793, 0.6054140031337738, 0.5892967641353607, 0.5758676409721375, 0.5644202351570129, 0.5546434760093689, 0.5461145341396332, 0.5384740769863129, 0.5315156698226928, 0.5252005994319916, 0.519519779086113, 0.5143065005540848, 0.5095425456762314, 0.5050577282905578, 0.5008695930242538, 0.4969203114509583, 0.4932731419801712, 0.48978383243083956, 0.48650614023208616, 0.4833309054374695]\n",
            "Validation_Loss [0.9920395851135254, 0.8082814276218414, 0.7223274111747742, 0.6699534893035889, 0.6336309671401977, 0.6067248165607453, 0.5859912514686585, 0.5692087233066558, 0.5554286420345307, 0.543598747253418, 0.5334197759628296, 0.5245422005653382, 0.5166591256856918, 0.5094736695289612, 0.5029786229133606, 0.4971209764480591, 0.49171328246593476, 0.48675676882267, 0.48212888836860657, 0.477821484208107, 0.4738013297319412, 0.47010171711444854, 0.46656609773635865, 0.4633099317550659, 0.4601560413837433]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Training and Testing Overfitting Model\n",
        "training_loss = []\n",
        "testing_loss = []\n",
        "validation_loss = []\n",
        "#---------------------\n",
        "model_overfit = OverfitNeuralNetwork().cuda()\n",
        "\n",
        "for epoch in range(25):\n",
        "  loss_per_epoch = 0\n",
        "  for idx, data in enumerate(train_loader):\n",
        "    features, labels = data\n",
        "    features = features.cuda()\n",
        "    labels = labels.cuda()\n",
        "    probs = model_overfit(features.reshape([-1, 784]))\n",
        "    loss = ce_loss(probs, labels)\n",
        "    loss_per_epoch = loss_per_epoch + loss.item()\n",
        "\n",
        "    for param in model_overfit.parameters():\n",
        "      param.grad = None\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    for name, param in model_overfit.named_parameters():\n",
        "      new_param = param - learning_rate * param.grad    \n",
        "      with torch.no_grad():\n",
        "        param.copy_(new_param)\n",
        "        \n",
        "  avg_loss_per_iter = loss_per_epoch/len(train_loader);\n",
        "  training_loss.append(avg_loss_per_iter)\n",
        "  \n",
        "  testing_loss_per_epoch = 0\n",
        "  for idx, data in enumerate(test_loader):\n",
        "    features, labels = data\n",
        "    features = features.cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      probs = model_overfit(features.reshape([-1, 784]))\n",
        "      predicts = torch.argmax(probs, dim=1)\n",
        "      tloss = ce_loss(probs, labels)\n",
        "      testing_loss_per_epoch = testing_loss_per_epoch + tloss.item()\n",
        "\n",
        "  avg_loss_per_iter = testing_loss_per_epoch/len(test_loader);\n",
        "  testing_loss.append(avg_loss_per_iter)\n",
        "\n",
        "  validation_loss_per_epoch = 0\n",
        "  for idx, data in enumerate(valid_loader):\n",
        "    features, labels = data\n",
        "    features = features.cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      probs = model_overfit(features.reshape([-1, 784]))\n",
        "      predicts = torch.argmax(probs, dim=1)\n",
        "      vloss = ce_loss(probs, labels)\n",
        "      validation_loss_per_epoch = validation_loss_per_epoch + vloss.item()\n",
        "\n",
        "  avg_loss_per_iter = validation_loss_per_epoch/len(valid_loader);\n",
        "  validation_loss.append(avg_loss_per_iter)\n",
        "\n",
        "print(f\"Training_Loss {training_loss}\")\n",
        "print(f\"Testing_Loss {testing_loss}\")\n",
        "print(f\"Validation_Loss {validation_loss}\")\n",
        "plt.plot(training_loss, label='Training Loss')\n",
        "plt.plot(validation_loss, label='Validation Loss')\n",
        "plt.plot(testing_loss, label='Testing Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1IolVlNOIQb"
      },
      "source": [
        "The general difference between overfitting and underfitting is that in case of underfitting the model cannot capture the complexity of the data leading to increase in training and test error thereby impacting the performance of the model. \n",
        "Whereas in case of the overfitting the model shows training error as almost negligible but when the model is run in real-life where the data is noisy. The overfitted model which leads to a very high training accuracy but very low test accuracy and high testing loss. This reduces the generalisation capacity of the model when it is run on the new testing data.\n",
        "\n",
        "Usually the model is underfit when it has less number of neurons per hidden layer or has less number of hidden layers in the network. \n",
        "Overfitting occurs when we increase the complexity of the network i.e be increasing the number of hidden layers in the network or increasing the number of neurons per layer. \n",
        "\n",
        "As can be seen above it is observed that when I decreased the number of neurons per layer in the UnderfitNeuralNetwork the training, testing as well as validation loss increases as compared to the loss we had when the number of neursons were more in our original model.\n",
        "\n",
        "Also, in case of overfitting I incresased the number of layers in the network thereby adding to the complexity of the network - class OverfitNeuralNetwork. This lead to the improvement in the training loss (it decreased from that of the original network) and then when the model was tested on the test load the testing loss increased. Leading to poor performance of the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTuC-FMBPbvI"
      },
      "source": [
        "Reference:\n",
        "\n",
        "\n",
        "1.   https://medium.com/unpackai/cross-entropy-loss-in-ml-d9f22fc11fe0 \n",
        "2.   https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function \n",
        "3.   https://en.wikipedia.org/wiki/One-hot \n",
        "4. https://medium.com/@xaviergeerinck/artificial-intelligence-how-to-measure-performance-accuracy-precision-recall-f1-roc-rmse-611d10e4caac\n",
        "5. https://torchmetrics.readthedocs.io/en/stable/classification/auroc.html\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
